# JusCash - Gerenciamento de Publica√ß√µes do DJE

Sistema para scraping, gerenciamento e visualiza√ß√£o de publica√ß√µes do Di√°rio da Justi√ßa Eletr√¥nico de S√£o Paulo.

## üåê Links do Projeto

- **Aplica√ß√£o Front-end**: [Acesse a aplica√ß√£o aqui](https://frontend.pedrohygorveras.ip-ddns.com/docs/)
- **Documenta√ß√£o da API**: [Swagger](https://backend.pedrohygorveras.ip-ddns.com/docs/)

Explore todos os endpoints da API de forma interativa.

---

## üìÇ Estrutura do Projeto

O projeto est√° dividido em tr√™s componentes principais:

1. **Crawler** (`/crawler`): Scraping do DJE utilizando Python.
2. **Backend** (`/backend`): API RESTful desenvolvida em Node.js.
3. **Frontend** (`/frontend`): Interface de usu√°rio baseada em React.js.

---

## üöÄ Tecnologias Utilizadas

- **Crawler**: Python, Selenium, BeautifulSoup.
- **Backend**: Node.js, Prisma ORM, PostgreSQL.
- **Frontend**: React.js, Vite, TailwindCSS.
- **Infraestrutura**: Docker e Docker Compose.

---

## üõ†Ô∏è Configura√ß√£o e Instala√ß√£o

### Pr√©-requisitos

Certifique-se de ter as seguintes ferramentas instaladas:

- [Docker](https://www.docker.com/) e [Docker Compose](https://docs.docker.com/compose/).

---

### 1. Clone o reposit√≥rio

```bash
git clone https://github.com/pedrohygorveras/app_publications.git
cd app_publications
```

---

### 2. Configure os arquivos .env

O projeto utiliza vari√°veis de ambiente para configurar suas depend√™ncias. Abaixo est√£o as configura√ß√µes necess√°rias:

#### Arquivo .env para o Backend (/backend/.env):

```env
DATABASE_URL="postgresql://admin:admin123@db_postgres:5432/db_publications?schema=public"
APP_VERSION=1.0.0
APP_NAME=JusCash
APP_PORT=3021
APP_HOST=0.0.0.0

# Seguran√ßa
SECRET=3cba8f43e8c94877a213f8d45c2f1b2e
SECRET_CRYPT=9fdf84a232df4b2d9f8e13a6d12c7d3e
REFRESH_TOKEN_SECRET=5ae9c78126e54fbab73a1b94c6eae987

# Configura√ß√£o de Token
TOKEN_LIFE=15m
REFRESH_TOKEN_LIFE=7d
```

#### Arquivo .env para o Frontend (/frontend/project/.env):

```env
docker-compose up --build
```

---

### 3. Execute o projeto com Docker Compose

Na raiz do projeto, execute o seguinte comando para iniciar todos os servi√ßos:

```bash
docker-compose up --build
```

Este comando ir√°:

- Construir e iniciar os containers do **Crawler**, **Backend** e **Frontend**.
- Configurar o banco de dados automaticamente.

---

### 4. Acesse o sistema

- **Frontend**: [http://localhost:3000](http://localhost:3000)
- **Backend** (Swagger): [http://localhost:3021/docs](http://localhost:3021/docs)

---

### 5. Como rodar o Crawler

1. **Entre no diret√≥rio do Crawler**:

   ```bash
   cd crawler
   ```

2. **Crie e ative um ambiente virtual**:

   Para Linux/Mac:

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

   Para Windows:

   ```bash
   python -m venv venv
   venv\Scripts\activate
   ```

3. **Instale as depend√™ncias**:

   ```bash
   pip install -r requirements.txt
   ```

4. **Edite os filtros (opcional)**:

   Os filtros para a busca podem ser configurados no arquivo `config/settings.py`:

   ```python
   URL = "https://dje.tjsp.jus.br"
   LOG_FILE = "./logs/scraper.log"
   OUTPUT_FILE = "./data/output.csv"
   FILTERS = {
       "dtInicio": "19/11/2024",
       "dtFim": "19/11/2024",
       "cadernos": "20",
       "pesquisaLivre": ["RPV", "pagamento pelo INSS"]
   }
   ```

   - **`dtInicio` e `dtFim`**: Per√≠odo de busca.
   - **`cadernos`**: Identifica√ß√£o do caderno de busca (ex.: "20").
   - **`pesquisaLivre`**: Termos de busca no conte√∫do das publica√ß√µes.

5. **Execute o script principal**:

   ```bash
   python main.py
   ```
